---
title: "Chapter 2: Exercises"
format: html
editor_options: 
  chunk_output_type: console
---

```{r}
library(tidyverse)
```

## Conceptual

### Question 1

For each of parts (a) through (d), indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible method. Justify your answer.

a)  The sample size $n$ is extremely large, and the number of predictors $p$ is small.
    -   **Flexible.** With a large sample size, we are free to use a flexible model as we can be more aware of the true relationship between the predictor(s) and response so to combat any bias from using an inflexible model.
b)  The number of predictors $p$ is extremely large, and the number of observations $n$ is small.
    -   **Inflexible.** Due to a low sample size, we would use an inflexible method so that if more samples are obtained, the model wouldn't be drastically effected, unless it was retrained in the future.
c)  The relationship between the predictors and response is highly non-linear.
    -   **Flexible.** If it is known that there is a highly non-linear relationship between the predictors and response, a flexible model should be used to reduce bias until there is a significant gain in variance.
d)  The variance of the error terms, i.e. $\sigma^2 = \text{Var}(\epsilon)$, is extremely high.
    -   **Inflexible.** If the variance of the error terms is inherently high, we would want a model that wouldn't be highly effected by a new set of training data.

### Question 2

Explain whether each scenario is a classification or regression problem, and indicate whether we are most interested in inference or prediction. Finally, provide $n$ and $p$.

a)  We collect a set of data on the top 500 firms in the US. For each firm, we record profit, number of employees, industry, and the CEO salary. We are interested in understanding which factors affect CEO salary.
    -   **Regression,** Inference, $n = 500$, $p = 3$
b)  We are considering launching a new product and wish to know whether it will be a *success* or a *failure*. We collect data on 20 similar products that were previously launched. For each product, we have recorded whether it was a success or failure, price charged for product, marketing budget, competition price, and ten other variables.
    -   **Classification,** Prediction, $n = 20$, $p = 13$
c)  We are interested in predicting the % change in the USD/Euro exchange rate in relation to the weekly changes in the world stock markets. Hence, we collect weekly data for all of 2012. For each week, we record the % change in the USD/Euro, the % change in the US market, the % change in the British market, and the % change in the German market.
    -   **Regression,** Prediction, $n = 52$, $p = 3$

### Question 3

We now revisit the bias-variance decomposition.

a)  Provide a sketch of typical (squared) bias, variance, training error, test error, and Bayes (or irreducible) error curves, on a single plot, as we go from less flexible statistical learning methods towards more flexible approaches. The x-axis should represent the amount of flexibility in the method, and the y-axis should represent the values for each curve. There should be five curves. Make sure to label each one.
    -   **Bias\^2:** The curve decrease as model flexibility increases.
    -   **Variance:** The curve increases as the model flexibility increases.
    -   **Training Error:** The curve decreases as model flexibility increases.
    -   **Test Error:** The curve first decreases, then increases, forming a "U" shape.
    -   **Bayes (Irreducible) Error:** The "curve" is a constant horizontal line.
b)  Explain why each of the five curves has the shape displayed in part (a).
    -   **Bias\^2:** More flexible models can better capture the underlying patterns in the data, reducing bias. Less flexible models (like linear models) oversimplify relationships, leading to high bias. As flexibility increases, bias tends to approach zero.
    -   **Variance:** As models become more flexible, they can more easily overfit to the noise in the training data, resulting in higher sensitivity to changes in the data (higher variance).
    -   **Training Error:** A more flexible model can better fit the training data, which leads to a reduction in the training error. Overly flexible models (overfit) can fit the (training) data perfectly, leading to almost no training error.
    -   **Test Error:** Initially, the model becomes better at capturing patterns in the data, reducing bias and test error. But, as the model becomes too flexible, it begins to overfit, causing the test error to increase due to high variance.
    -   **Bayes (Irreducible) Error:** This error represents the minimum error achievable given the inherent noise in the data. It does not change with model flexibility as it is a fundamental limit based on the data noise and randomness.

### Question 4

You will now think of some real-life applications for statistical learning.

a)  Describe three real-life applications in which *classification* might be useful. Describe the response, as well as the predictors. Is the goal of each application inference or prediction? Explain your answer.
    -   **Email Spam Detection**
        -   **Response:** If an email is spam or not.
        -   **Predictors:** Email text, attachments, links, sender address.
        -   **Goal:** **Prediction** - understanding which predictors affect the outcome is less important than accurately classifying new emails.
    -   **Medical Diagnosis**
        -   **Response:** Whether the patient has diabetes (TRUE or FALSE).
        -   **Predictors:** Blood glucose levels, BMI, age, smoking status.
        -   **Goal:** **Prediction** - goal is to classify new patients on if they have diabetes or not, based on historical data. Inference on predictors may help, but main focus is prediction accuracy.
    -   **Credit Card Fraud Detection**
        -   **Response:** Whether a credit card transaction is fraudulent or not.
        -   **Predictors:** Transaction amount, location, time, merchant, previous transaction patterns.
        -   **Goal:** **Prediction** - goal is to predict if a transaction is fraudulent in real time. Preventing fraud is the highest priority.
b)  Describe three real-life applications in which *regression* might be useful. Describe the response, as well as the predictors. Is the goal of each application inference or prediction? Explain your answer.
    -   **House Price Prediction**
        -   **Response:** The price of a house
        -   **Predictors:** Square footage, number of bedrooms, location, age of the house, nearby amenities.
        -   **Goal:** **Prediction** – The primary goal is to predict the selling price of a house based on its features. While understanding the influence of individual predictors could be useful for insights, the focus is on making accurate price predictions.
    -   **Estimating a Company's Revenue**
        -   **Response:** Annual revenue
        -   **Predictors:** Marketing spend, number of employees, industry trends, competitor data, product portfolio.
        -   **Goal:** **Inference** – The goal might be to understand how different predictors (like marketing spend) influence revenue. This information could guide decisions on how to allocate resources in the future.
    -   **Predicting Future Sales of a Product.**
        -   **Response:** Monthly sales figures
        -   **Predictors:** Price, advertising budget, seasonality, competitor prices, economic indicators.
        -   **Goal:** **Prediction** – The goal is to predict future sales to optimize inventory and resource allocation. Understanding the relationships between predictors may be helpful, but the primary goal is accurate forecasting.
c)  Describe three real-life applications in which *cluster analysis* might be useful.
    -   **Customer Segmentation**
        -   **Application:** Identifying distinct groups of customers based on purchasing behavior, demographics, or preferences.
        -   **Usage:** This can be used by marketers to tailor campaigns and promotions to different customer groups.
    -   **Document Clustering**
        -   **Application:** Grouping documents (e.g., research papers or articles) based on similarity in content or topic.
        -   **Usage:** This helps in organizing large volumes of text data into meaningful categories for easier retrieval or summarization.
    -   **Social Media User Profiling**
        -   **Application:** Grouping social media users based on behavior, interests, and interactions (e.g., identifying clusters of influencers, casual users, or niche communities).
        -   **Usage:** This can help companies target specific user groups with personalized content or advertisements.

### Question 5

What are the advantages and disadvantages of a very flexible vs less flexible approach for classification. Under what circumstances might a more flexible approach be preferred to a less flexible approach? When might a less flexible approach be preferred?

### Question 6

Describe the difference between a parametric and a non-parametric statistical learning approach. What are the advantages of a parametric approach to a regression or classification, as opposed to a non-parametric approach? What are its disadvantages?

**Parametric Methods**

**Definition:** Parametric methods make a strong assumption about the functional form or shape of the relationship between the predictors and the response variable. For example, linear regression assumes that the relationship is linear.

**Advantages:**

-   **Simplicity:** Parametric methods reduce the problem of learning to estimating a small number of parameters. This simplifies computation and interpretation, as the relationship is summarized by a fixed number of coefficients.
-   **Efficiency:** Because the model is based on a specific form (e.g., linear), parametric approaches often require fewer data points to achieve accurate estimates.
-   **Interpretability:** Parametric models are typically easier to interpret since we can directly look at coefficients to understand the influence of each predictor.

**Disadvantages:**

-   **Model Misspecification:** The primary drawback is that parametric methods rely on the correct assumption about the form of the relationship. If the true relationship does not match the assumed form (e.g., the relationship is non-linear but the model assumes linearity), the model will exhibit **high bias** and fail to capture the underlying patterns.
-   **Inflexibility:** Parametric models are less flexible, meaning they can’t adapt well to data that doesn’t fit the assumed form, leading to poor performance when the true relationship is more complex.

**Non-Parametric Methods**

**Definition:** Non-parametric methods make fewer assumptions about the functional form of the relationship between predictors and the response. Examples include K-nearest neighbors (KNN), decision trees, and kernel regression. These methods aim to let the data dictate the structure of the relationship.

**Advantages:**

-   **Flexibility:** Non-parametric methods can fit a broader range of functional forms, adapting to more complex, non-linear relationships between predictors and response. They are particularly useful when the true form of the relationship is unknown or difficult to specify.
-   **Fewer Assumptions:** Because there’s no assumption about the shape of the function, non-parametric methods are less likely to suffer from bias due to incorrect model assumptions. -

**Disadvantages:**

-   **Data Hungry:** Non-parametric models generally require a large number of observations to produce accurate estimates, especially in high-dimensional settings. This is because they need enough data to approximate the true form without a predefined structure.
-   **Overfitting:** Non-parametric methods, due to their flexibility, are prone to overfitting, especially when the number of observations is small. They can capture noise in the training data rather than just the underlying pattern.
-   **Interpretability:** These models can be more challenging to interpret, as they don't provide simple, closed-form expressions for the relationships between predictors and response like parametric models do.

**Summary:**

-   **Parametric methods** are best when the form of the relationship is known or relatively simple, and interpretability is key.
-   **Non-parametric methods** are best when the relationship is complex and unknown, but they require a lot of data and can be prone to overfitting.

### Question 7

The table below provides a training data set containing six observations, three predictors, and one qualitative response variable. Suppose we wish to use this data set to make a prediction for $Y$ when $X_1 = X_2 = X_3 = 0$ using $K$-nearest neighbors.

| Obs. | $X_1$ | $X_2$ | $X_3$ |  $Y$  |
|:----:|:-----:|:-----:|:-----:|:-----:|
|  1   |   0   |   3   |   0   |  Red  |
|  2   |   2   |   0   |   0   |  Red  |
|  3   |   0   |   1   |   3   |  Red  |
|  4   |   0   |   1   |   2   | Green |
|  5   |  -1   |   0   |   1   | Green |
|  6   |   1   |   1   |   1   |  Red  |

a)  Compute the Euclidean distance between each observation and the test point, $X_1 = X_2 = X_3 = 0$.
    -   **{3, 2, 3.16, 2.24, 1.41, 1.73}**
b)  What is our prediction with $K = 1$? Why?
    -   **Green:** The nearest observation is Obs. 5
c)  What is our prediction with $K = 3$? Why?
    -   **Red:** The three nearest observations are 5, 6, & 2, with 2/3 of them being Red.
d)  If the Bayes decision boundary in this problem is highly non-linear, then would we expect the *best* value for $K$ to be large or small? Why?
    -   **Small:** If the Bayes decision boundary is highly non-linear, a small value of $K$ allows for a more flexible model that can capture the non-linear patterns in the data. A larger $K$ would result in a smoother decision boundary, which can approximate a linear boundary in some cases, but would fail the non-linear boundary in this case.

```{r}
#| label: q7

q7 = tibble(
  x1 = c(0, 2, 0, 0,-1, 1),
  x2 = c(3, 0, 1, 1, 0, 1),
  x3 = c(0, 0, 3, 2, 1, 1),
  Y = c("Red", "Red", "Red", "Green", "Green", "Red")
) |> 
  mutate(observation = row_number(), .before = 1)

q7 = q7 |>
  select(starts_with("x")) |> 
  pmap(\(x1, x2, x3) sqrt(x1^2 + x2^2 + x3^2)) |> 
  list_c() |> 
  as_tibble_col("euc_dist") |> 
  bind_cols(q7)

# A
q7 |> select(observation, euc_dist)
  
# B
q7 |> 
  slice_min(euc_dist, n = 1) |> 
  slice_max(Y, n = 1) |> 
  pull(Y)

# C
q7 |> 
  slice_min(euc_dist, n = 3) |> 
  mutate(.by = Y, count = n()) |> 
  slice_max(count, n = 1)
```

## Applied

### Question 8

This exercise relates to the `College` data set, which can be found in the file `College.csv` on the book website. It contains a number of variables for 777 different universities and colleges in the US.

a)  Use the `read.csv()` function to read the data in `R`. Call the loaded data `college`. Make sure that you have the directory set to the correct location for the data.

```{r}
#| label: q8-a

college = ISLR2::College
```

b)  Look at the data using the `View()` function. You should notice that the first column is just the name of each university. We don't really want `R` to treat this as data. However, it may be handy to have these names for later. Try the following command: `rownames(college <- college[, 1])`. you should see that there is now a `row.names` column with the name of each university recorded. This means that `R` has given each row a name corresponding to the appropriate university. `R` will not try to perform calculations on the row names. However, we still need to eliminate the first column in the data where the names are stored. Try: `college <- college[, -1]`. Now you should see that the first column is `Private`. Note that another column labeled `row.names` now appears before the `Private` column. However, this is not a data column, but rather a the name that `R` is giving to each row.

```{r}
#| label: q8-b

View(college)
college = as_tibble(ISLR2::College, rownames = "college") |> 
  janitor::clean_names()
```

c)  This is multi-part:
    i.  Use the `summary()` function to produce a numerical summary of the variables in the data set.
    ii. Use the `pairs()` function to produce a scatterplot matrix of the first ten columns or variables of the data. Recall that you can reference the first ten columns of a matrix `A` using `A[,1:10]`.
    iii. Use the `plot()` function to produce side-by-side boxplots of `Outstate` versus `Private`.
    iv. Create a new qualitative variable, called `Elite`, by *binning* the `Top10perc` variable. We are going to divide universities into two groups based on whether or not the proportion of students coming from the top 10 % of their high school classes exceeds 50 %. Use the `summary()` function to see how many elite universities there are. Now use the `plot()` function to produce side-by-side boxplots of `Outstate` versus `Elite`.
    v.  Use the `hist()` function to produce some histograms with differing numbers of bins for a few of the quantitative variables. You may find the command `par(mfrow = c(2, 2))` useful: it will divide the print window into four regions so that four plots can be made simultaneously. Modifying the arguments to this function will divide the screen in other ways.
    vi. Continue exploring the data, and provide a brief summary of what you discover.

```{r}
#| label: q8-c

# i
summary(college)
skimr::skim(college)

# ii
college |> 
  mutate(private = if_else(TRUE, 1, 0)) |> 
  select(where(is.numeric)) |> 
  select(1:10) |>  
  GGally::ggpairs(lower = list(continuous = "smooth"))

# iii
college |>
  ggplot(aes(outstate, private)) +
  geom_boxplot()

# iv
college = college |> 
  mutate(
    elite = fct(
      if_else(top10perc > 50, "Yes", "No"), 
      levels = c("Yes", "No")
    )
  )

summary(college) # Elite; Yes: 78, No: 699

college |>
  ggplot(aes(outstate, elite)) +
  geom_boxplot()

# v
multi_hist = function(var, bins) {
  plot = college |>
    ggplot(aes(x = !!sym(var))) +
    geom_histogram(bins = bins) +
    labs(title = str_c("Histogram of ", var, " with ", bins, " bins")) +
    theme_minimal()
  
  print(plot)
}

crossing(
  var = college |> select(apps, outstate, books) |> names(),
  bins = c(5, 10, 15, 20)
) |> 
  pwalk(multi_hist)

# vi
college |> 
  ggplot(aes(grad_rate, elite)) +
  geom_boxplot()

# It seems on the surface the "elite" university students are better at graduating 

college |> 
  filter(grad_rate > 100) |> 
  select(college, grad_rate)

# Cazenovia College might need to get better at math
```

### Question 9

This exercise involves the `Auto` data set studied in the lab. Make sure that the missing values have been removed from the data.

a)  Which of the predictors are quantitative, and which are qualitative?

```{r}
#| label: q9-a

auto = as_tibble(ISLR2::Auto) |> 
  filter(!if_any(everything(), is.na)) |> 
  mutate(
    cylinders = as_factor(cylinders),
    year = ym(str_c("19", year, "-01")),
    origin = origin |> 
      case_match(
        1 ~ "American",
        2 ~ "European",
        3 ~ "Japanese"
      ) |> 
      fct()
  )

auto |> 
  select(where(is.numeric)) |> 
  names() |> 
  as_tibble_col("quantitative") |> 
  print()

auto |> 
  select(!where(is.numeric)) |> 
  names() |> 
  as_tibble_col("qualitative") |> 
  print()
```

b)  What is the range of each quantitative predictor? You can answer this using the `range()` function.

```{r}
#| label: q9-b

auto |> 
  select(where(is.numeric)) |> 
  map(range)
```

c)  What is the mean and standard deviation of each quantitative predictor?

```{r}
#| label: q9-c

auto |> 
  select(where(is.numeric)) |> 
  map(\(col) list(mean = mean(col), sd = sd(col)))
```

d)  Now remove the 10th through 85th observations. What is the range, mean, and standard deviation of each predictor in the subset of the data that remains?

```{r}
#| label: q9-d

auto |> 
  select(where(is.numeric)) |> 
  mutate(row_number = row_number()) |> 
  slice(-(10:85)) |> 
  map(\(col) list(range = range(col), mean = mean(col), sd = sd(col)))
```

e)  Using the full data set, investigate the predictors graphically, using scatterplots or other tools of your choice. Create some plots highlighting the relationships among the predictors. Comment on your findings.

```{r}
#| label: q9-e

auto |> 
  select(-name) |> 
  GGally::ggpairs()
```

-   There is a strong negative correlation between `mpg` and `displacement`, `horsepower`, & `weight`
-   American cars tend to be much bigger than European and Japanese, probably due to the popularity of trucks, which is supported by the higher displacement and horsepower of American cars. This intern gives American cars the worst `mpg`.
-   `acceleration` has a relatively normal distribution across all vehicles.

f)  Suppose that we wish to predict gas mileage, `mpg`, on the basis of the other variables. Do you plots suggest that any of the other variables might be useful in predicting `mpg`? Justify your answer.
    -   **Yes**.
    -   As stated above, there is a strong negative correlation between `mpg` and `displacement`, `horsepower`, & `weight`.
    -   American cars on average have far lower `mpg` than Japanese or European cars.

### Question 10

This exercise involves the `Boston` housing data set.

a.  To being, load the `Boston` data set. How many rows are in this data set? How many columns? What do the rows and columns represent?

```{r}
#| label: q10-a

boston = as_tibble(ISLR2::Boston) |> 
  mutate(
    chas = if_else(chas == 1, TRUE, FALSE),
    rad = as_factor(rad)
  )

nrow(boston) # 506 rows
ncol(boston) # 13 cols
```

This table represents 506 different suburbs in Boston, with each column representing a different feature or statistic about the suburb.

b.  Make some pairwise scatterplots of the predictors (columns) in this data set. Describe your findings.

```{r}
#| label: q10-b

boston |> 
  GGally::ggpairs()
```

-   There is a strong positive correlation between `rm` and `medv`
-   `rm` has a strong normal distribution
-   `indus` and `tax` seem to be bi-modal
-   `medv` has a normal distribution around but is skewed right.
-   `rad` = 25 has much higher `crim` values than any other `rad` values

c.  Are any of the predictors associated with per capita crime rate? If so, explain the relationship.

```{r}
#| label: q10-c

boston |> 
  select(-crim) |> 
  names() |> 
  walk(\(col) {
    plot = boston |> 
      ggplot(aes(!!sym(col), crim)) +
      geom_point(alpha = 0.5) +
      geom_smooth() +
      labs(title = str_c("crim vs ", col))
    
    print(plot)
  })
```

-   `medv` < 20 seems to indicate higher crime, with also a jump at `medv` == 50
-   `rad` == 24 is a strong indicator of crime
-   relative closeness to employment centers, `dis` < 3, is an indicator
-   `chas` value, aka touching the Chase river or not is a strong indicator
-   Very low `zn` is a strong indicator of high crime

d.  Do any of the census tracts of Boston appear to have particularly high crime rates? Tax rates? Pupil-teacher ratios? Comment on the range of each predictor.

```{r}
#| label: q10-d

deciles = as_factor(names(quantile(boston$tax, probs = seq(0, 1, 1/10))))

# ---

quantile(boston$crim, probs = seq(0, 1, 1/10)) 
range(boston$crim)

ggplot(data = tibble(
  value = quantile(boston$crim, probs = seq(0, 1, 1/10)),
  decile = deciles
)) + 
  geom_col(aes(decile, value))
# The top 10% of high crime areas have almost 8X the crime rate as the bottom 90%. 
# Very high range of [0.00632, 88.97620]

# ---
quantile(boston$tax, probs = seq(0, 1, 1/10)) 
range(boston$tax)

ggplot(data = tibble(
  value = quantile(boston$tax, probs = seq(0, 1, 1/10)),
  decile = deciles
)) + 
  geom_col(aes(decile, value))
# Taxes seem to increase linearly until the 80% decile where there is a big jump
# Big range of [187, 711]

# ---
quantile(boston$ptratio, probs = seq(0, 1, 1/10)) 
range(boston$ptratio)

ggplot(data = tibble(
  value = quantile(boston$ptratio, probs = seq(0, 1, 1/10)),
  decile = deciles
)) + 
  geom_col(aes(decile, value))
# The bottom 50% have a high range of values, 13 to 19, where the top 50% center around 20-22
# Modest range of [12.6, 22.0]
```

e.  How many of the census tracts in this data set bound the Charles river?

```{r}
#| label: q10-e

boston |> count(chas) # 35
```

f.  What is the median pupil-teacher ratio among the towns in this data set?

```{r}
#| label: q10-f

median(boston$ptratio) # 19.05
```

g.  Which census tract of Boston has the lowest median value of owner-occupied homes? What are the values of the other predictors for that census tract, and how do those values compare to the overall ranges for those predictors? Comment on your findings.

```{r}
#| label: q10-g

boston |> 
  mutate(row = row_number(), .before = 1) |> 
  slice_min(medv, n = 1, with_ties = FALSE)

ranges = boston |> 
  slice(-399) |> 
  select(-medv) |> 
  select(where(is.numeric)) |> 
  map(\(col) tibble(min = min(col), max = max(col))) |> 
  imap(\(x, idx) x |> mutate(name = idx)) |> 
  list_rbind()

lowest = boston |> 
  slice_min(medv, n = 1, with_ties = FALSE) |> 
  select(-medv) |> 
  select(where(is.numeric)) |> 
  pivot_longer(
    cols = everything(), 
    values_to = "lowest_medv",
    names_to = "name")

ranges |> 
  left_join(lowest, join_by(name)) |> 
  select(name, min, lowest_medv, max)
```

-   For `zn` & `dis`, the census tract was almost identical to the minimum.
-   For `age`, `tax`, `ptratio`, & `lstat`, the census track was much closer to the maximums.
-   For `crim`, `indus`, & `nox`, the census track is in the middle.

h.  In this data set, how many of the census tracts average more than seven rooms per dwelling? More than eight rooms per dwelling? Comment on the census tracts that average more than eight rooms per dwelling.

```{r}
#| label: q10-h

boston |> filter(rm > 7) |> nrow() # 64
boston |> filter(rm > 8) |> nrow() # 13

boston |> filter(rm > 8)
```

The census tracks with more than eight rooms per dwelling on average have very low crime rates.
